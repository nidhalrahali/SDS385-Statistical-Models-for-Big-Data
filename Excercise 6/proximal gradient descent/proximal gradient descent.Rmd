---
title: "Proximal gradient descent"
author: "Yinan Zhu"
date: "October 17, 2017"
output: html_document
---

```{r}
library(glmnet)
source('~/GitHub/SDS385-course-work/Excercise 6/proximal gradient descent/functions.R')
X <- read.csv("~/GitHub/SDS385-course-work/Excercise 6/proximal gradient descent/diabetesX.csv", header=TRUE)
Y = read.csv("~/GitHub/SDS385-course-work/Excercise 6/proximal gradient descent/diabetesY.csv", header=FALSE)
X = as.matrix(X)
X = scale(X)
X=cbind(1,X)
Y = Y$V1
Y = as.vector(scale(Y))
n=length(Y)
p=ncol(X)
```
```{r}
lam=seq(from=0.001,to=0.6,by=0.005)
```
```{r}
beta0=rep(0,p)
lambda=0.001
gamma=0.1
ite=200
```

```{r}
result=prox_gd(X,Y,beta0,lambda,gamma,ite)
plot(result$targetfunction,type='l',xlab='iteration',ylab='target function')
```


```{r}
mse=rep(0,0)
betahistory=matrix(nrow=0,ncol=p)
for(lambda in lam){
  result=prox_gd(X,Y,beta0,lambda,gamma,ite)
  betahistory=rbind(betahistory,result$beta)
  mse=c(mse,target_function(X,Y,result$beta,0))
}
plot(mse~lam,type='l',xlab='lambda')
```
```{r}
plot(0,type='l',xlim=c(-7,0),ylim=c(-0.4,0.4),ylab='coefficient',xlab='log(lambda)')
for(i in 2:ncol(betahistory)){
  lines(betahistory[,i]~log(lam))
}
```

```{r}
m = glmnet(X,Y,lambda=lam)
yhat=predict(m,newx=X)
plot(colMeans((Y-yhat)^2)~m$lambda,type='l',ylab='mse',xlab='lambda')
```
```{r}
plot.glmnet(m,xvar='lambda')
```


